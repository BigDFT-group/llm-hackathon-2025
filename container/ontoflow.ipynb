{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de35cca9-2866-4b04-a6f6-12f49e367a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/work/2-aiengine/OntoFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74f60a7-98d6-4a07-8d67-d688aace6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ontoflow_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd9251c-5afe-4470-b7ae-08d8c51c7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.13/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ OntoRAG Magic prête. Initialisation au premier usage...\n"
     ]
    }
   ],
   "source": [
    "%load_ext Onto_RAG_with_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccf5710-3504-4862-8a56-8c100e93999f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_filenames = [\n",
    "    \"01-QuickStart.ipynb\", \"02-N2.ipynb\", \"03-BasisSetConvergence.ipynb\",\n",
    "    \"04-BasisSetComparison.ipynb\", \"05-LinearScaling-QuickStart.ipynb\",\n",
    "    \"06-LinearScaling.ipynb\"\n",
    "]\n",
    "DOCUMENTS = [{\n",
    "    \"filepath\": os.path.join(ontoflow_dir, \"..\", \"1-humandoc\", fname),\n",
    "    \"project_name\": \"BigDFT\",\n",
    "    \"version\": \"1.9\"\n",
    "} for fname in doc_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7d40e-756e-4ab5-9bef-c2bbabca3517",
   "metadata": {},
   "source": [
    "**Make the agent aware of the Jupyter notebooks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b793861-d895-4bcf-9037-ab169004526d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initialisation du moteur OntoRAG (une seule fois)...\n",
      "🚀 Initialisation d'OntoRAG...\n",
      "📚 Chargement de l'ontologie: bigdft_ontologie_ipynb.ttl\n",
      "Concept enrichi: FFT Operation - Fast Fourier Transform applied to data on regular ...\n",
      "Concept enrichi: Poisson Solver - Numerical solution of the Poisson equation, for ca...\n",
      "Concept enrichi: Data Extraction - None\n",
      "Concept enrichi: Memory Management - Concepts related to controlling and optimizing mem...\n",
      "Concept enrichi: DFT Concept - None\n",
      "Concept enrichi: Lesson - A document explaining a broader theoretical concep...\n",
      "Concept enrichi: Visualization - None\n",
      "Concept enrichi: Tutoriel - A step-by-step guide to perform a specific task us...\n",
      "Concept enrichi: Concept de Performance - None\n",
      "Concept enrichi: Post-Processing - None\n",
      "Concept enrichi: Configuration de Calcul - None\n",
      "Concept enrichi: Example - A focused code snippet demonstrating a specific fe...\n",
      "Concept enrichi: Algorithmic Concept - None\n",
      "Concept enrichi: Document - A document providing information about BigDFT.\n",
      "Concept enrichi: Linear Scaling Method - An algorithm whose computational cost scales linea...\n",
      "Concept enrichi: Electron Density - Spatial density of electrons in a quantum system, ...\n",
      "Concept enrichi: Vectorization - Improving performance by using array-based operati...\n",
      "Concept enrichi: Exchange-Correlation Functional - The component of DFT that models complex electron ...\n",
      "Concept enrichi: Concept d'Utilisation - None\n",
      "Concept enrichi: Matrix Operation - Operations involving matrices (e.g., multiplicatio...\n",
      "Concept enrichi: Geometry Optimization - A process to find the minimum energy conformation ...\n",
      "Concept enrichi: Concept Physique - None\n",
      "Concept enrichi: PyBigDFT API Object - Represents a key class or object in the PyBigDFT P...\n",
      "Concept enrichi: Molecular Dynamics - A method for simulating the physical motion of ato...\n",
      "Concept enrichi: Self-Consistent Field (SCF) Cycle - The iterative procedure for solving the Kohn-Sham ...\n",
      "Concept enrichi: Pseudopotential - An effective potential that simplifies core electr...\n",
      "Concept enrichi: Basis Set - A set of functions used to represent electronic or...\n",
      "Concept enrichi: Wavefunction - Mathematical function representing the quantum sta...\n",
      "Concept enrichi: Parallelization - Describes how to run calculations in parallel (e.g...\n",
      "✓ 29/29 concepts enrichis avec succès\n",
      "✅ Ontologie chargée: 29 concepts, 4 relations\n",
      "Métadonnées chargées: 6 documents\n",
      "✅ RAG engine assigné au concept_classifier\n",
      "✅ classify_embedding_direct disponible\n",
      "✅ RAG engine assigné au classifier hiérarchique\n",
      "Initialisation du classifieur de concepts hiérarchique...\n",
      "Construction de la hiérarchie pour 29 concepts\n",
      "Relation subClassOf: Tutoriel -> Document\n",
      "Relation subClassOf: Lesson -> Document\n",
      "Relation subClassOf: Example -> Document\n",
      "Relation subClassOf: Configuration de Calcul -> Concept d'Utilisation\n",
      "Relation subClassOf: Post-Processing -> Concept d'Utilisation\n",
      "Relation subClassOf: PyBigDFT API Object -> Concept d'Utilisation\n",
      "Relation subClassOf: Visualization -> Post-Processing\n",
      "Relation subClassOf: Data Extraction -> Post-Processing\n",
      "Relation subClassOf: DFT Concept -> Concept Physique\n",
      "Relation subClassOf: Molecular Dynamics -> Concept Physique\n",
      "Relation subClassOf: Geometry Optimization -> Concept Physique\n",
      "Relation subClassOf: Wavefunction -> DFT Concept\n",
      "Relation subClassOf: Electron Density -> DFT Concept\n",
      "Relation subClassOf: Exchange-Correlation Functional -> DFT Concept\n",
      "Relation subClassOf: Basis Set -> DFT Concept\n",
      "Relation subClassOf: Pseudopotential -> DFT Concept\n",
      "Relation subClassOf: Self-Consistent Field (SCF) Cycle -> DFT Concept\n",
      "Relation subClassOf: Matrix Operation -> Algorithmic Concept\n",
      "Relation subClassOf: FFT Operation -> Algorithmic Concept\n",
      "Relation subClassOf: Poisson Solver -> Algorithmic Concept\n",
      "Relation subClassOf: Linear Scaling Method -> Algorithmic Concept\n",
      "Relation subClassOf: Parallelization -> Concept de Performance\n",
      "Relation subClassOf: Memory Management -> Concept de Performance\n",
      "Relation subClassOf: Vectorization -> Concept de Performance\n",
      "✓ Hiérarchie de concepts construite avec 29 concepts sur 3 niveaux\n",
      "  - Niveau 2: 16 concepts\n",
      "  - Niveau 3: 8 concepts\n",
      "  - Niveau 1: 5 concepts\n",
      "✓ Réseau de concepts niveau 1 chargé (mode classique)\n",
      "✓ Réseau de concepts niveau 2 chargé (mode classique)\n",
      "✓ Réseau de concepts niveau 3 chargé (mode classique)\n",
      "✓ Embeddings de 29 concepts chargés\n",
      "📚  Ajout des concepts biblio : 5 à entraîner\n",
      "❌ Aucune injection de concept 'ConceptHopfieldClassifier' object has no attribute 'add_new_concepts'\n",
      "✅ Classifieur ontologique initialisé\n",
      "Initialisation du stockage de documents...\n",
      "Documents trouvés dans les métadonnées: 6\n",
      "Chargement du document _work_1-humandoc_03-BasisSetConvergence.ipynb...\n",
      "Chargement de 4 chunks pour document _work_1-humandoc_03-BasisSetConvergence.ipynb.\n",
      "Document _work_1-humandoc_03-BasisSetConvergence.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_01-QuickStart.ipynb...\n",
      "Chargement de 4 chunks pour document _work_1-humandoc_01-QuickStart.ipynb.\n",
      "Document _work_1-humandoc_01-QuickStart.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_04-BasisSetComparison.ipynb...\n",
      "Chargement de 8 chunks pour document _work_1-humandoc_04-BasisSetComparison.ipynb.\n",
      "Document _work_1-humandoc_04-BasisSetComparison.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb...\n",
      "Chargement de 5 chunks pour document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb.\n",
      "Document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_02-N2.ipynb...\n",
      "Chargement de 7 chunks pour document _work_1-humandoc_02-N2.ipynb.\n",
      "Document _work_1-humandoc_02-N2.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_06-LinearScaling.ipynb...\n",
      "Chargement de 14 chunks pour document _work_1-humandoc_06-LinearScaling.ipynb.\n",
      "Document _work_1-humandoc_06-LinearScaling.ipynb chargé avec succès.\n",
      "Initialisation du classifieur de concepts hiérarchique...\n",
      "Construction de la hiérarchie pour 29 concepts\n",
      "Relation subClassOf: Tutoriel -> Document\n",
      "Relation subClassOf: Lesson -> Document\n",
      "Relation subClassOf: Example -> Document\n",
      "Relation subClassOf: Configuration de Calcul -> Concept d'Utilisation\n",
      "Relation subClassOf: Post-Processing -> Concept d'Utilisation\n",
      "Relation subClassOf: PyBigDFT API Object -> Concept d'Utilisation\n",
      "Relation subClassOf: Visualization -> Post-Processing\n",
      "Relation subClassOf: Data Extraction -> Post-Processing\n",
      "Relation subClassOf: DFT Concept -> Concept Physique\n",
      "Relation subClassOf: Molecular Dynamics -> Concept Physique\n",
      "Relation subClassOf: Geometry Optimization -> Concept Physique\n",
      "Relation subClassOf: Wavefunction -> DFT Concept\n",
      "Relation subClassOf: Electron Density -> DFT Concept\n",
      "Relation subClassOf: Exchange-Correlation Functional -> DFT Concept\n",
      "Relation subClassOf: Basis Set -> DFT Concept\n",
      "Relation subClassOf: Pseudopotential -> DFT Concept\n",
      "Relation subClassOf: Self-Consistent Field (SCF) Cycle -> DFT Concept\n",
      "Relation subClassOf: Matrix Operation -> Algorithmic Concept\n",
      "Relation subClassOf: FFT Operation -> Algorithmic Concept\n",
      "Relation subClassOf: Poisson Solver -> Algorithmic Concept\n",
      "Relation subClassOf: Linear Scaling Method -> Algorithmic Concept\n",
      "Relation subClassOf: Parallelization -> Concept de Performance\n",
      "Relation subClassOf: Memory Management -> Concept de Performance\n",
      "Relation subClassOf: Vectorization -> Concept de Performance\n",
      "✓ Hiérarchie de concepts construite avec 29 concepts sur 3 niveaux\n",
      "  - Niveau 2: 16 concepts\n",
      "  - Niveau 3: 8 concepts\n",
      "  - Niveau 1: 5 concepts\n",
      "✓ Réseau de concepts niveau 1 chargé (mode classique)\n",
      "✓ Réseau de concepts niveau 2 chargé (mode classique)\n",
      "✓ Réseau de concepts niveau 3 chargé (mode classique)\n",
      "✓ Embeddings de 29 concepts chargés\n",
      "📚  Ajout des concepts biblio : 5 à entraîner\n",
      "❌ Aucune injection de concept 'ConceptHopfieldClassifier' object has no attribute 'add_new_concepts'\n",
      "✅ Classifieur ontologique initialisé\n",
      "✅ Classifier lié à l'ontology_manager\n",
      "✅ RAG engine lié à l'ontology_manager\n",
      "✅ Navigateur ontologique configuré\n",
      "✅ Composants ontologiques configurés dans le processeur\n",
      "✅ Ontology_manager assigné au processeur\n",
      "Initialisation du stockage de documents...\n",
      "Documents trouvés dans les métadonnées: 6\n",
      "Chargement du document _work_1-humandoc_03-BasisSetConvergence.ipynb...\n",
      "Document _work_1-humandoc_03-BasisSetConvergence.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_01-QuickStart.ipynb...\n",
      "Document _work_1-humandoc_01-QuickStart.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_04-BasisSetComparison.ipynb...\n",
      "Document _work_1-humandoc_04-BasisSetComparison.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb...\n",
      "Document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_02-N2.ipynb...\n",
      "Document _work_1-humandoc_02-N2.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_06-LinearScaling.ipynb...\n",
      "Document _work_1-humandoc_06-LinearScaling.ipynb chargé avec succès.\n",
      "✅ Module Fortran initialisé\n",
      "Initialisation du stockage de documents...\n",
      "Documents trouvés dans les métadonnées: 6\n",
      "Chargement du document _work_1-humandoc_03-BasisSetConvergence.ipynb...\n",
      "Document _work_1-humandoc_03-BasisSetConvergence.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_01-QuickStart.ipynb...\n",
      "Document _work_1-humandoc_01-QuickStart.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_04-BasisSetComparison.ipynb...\n",
      "Document _work_1-humandoc_04-BasisSetComparison.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb...\n",
      "Document _work_1-humandoc_05-LinearScaling-QuickStart.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_02-N2.ipynb...\n",
      "Document _work_1-humandoc_02-N2.ipynb chargé avec succès.\n",
      "Chargement du document _work_1-humandoc_06-LinearScaling.ipynb...\n",
      "Document _work_1-humandoc_06-LinearScaling.ipynb chargé avec succès.\n",
      "✅ Module jupyter initialisé\n",
      "✅ OntoRAG initialisé avec succès!\n",
      "✅ Moteur OntoRAG initialisé et prêt.\n",
      "📚 Ajout de 6 documents...\n",
      "📄 01-QuickStart.ipynb - Aucun changement détecté\n",
      "📄 02-N2.ipynb - Aucun changement détecté\n",
      "📄 03-BasisSetConvergence.ipynb - Aucun changement détecté\n",
      "📄 04-BasisSetComparison.ipynb - Aucun changement détecté\n",
      "📄 05-LinearScaling-QuickStart.ipynb - Aucun changement détecté\n",
      "📄 06-LinearScaling.ipynb - Aucun changement détecté\n",
      "✅ Relations entre entités reconstruites\n",
      "🔄 Synchronisation des index de recherche...\n",
      "✅ Index de recherche synchronisés\n",
      "📊 Traitement terminé: 6/6 fichiers ajoutés avec succès\n",
      "✅ Ajout terminé: 6/6 succès.\n"
     ]
    }
   ],
   "source": [
    "%rag /add_docs DOCUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc79973-a087-4383-9d07-1c316792f5a0",
   "metadata": {},
   "source": [
    "**Now that the documents have been taken into account, we can start discussing with the agent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d119dc5-a388-451a-b26f-67feb2821f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💫 Commande : /agent how can I build a system from two fragments with the Python BigDFT module?\n",
      "🧠 L'agent réfléchit...\n",
      "  🔄 Index vide, construction automatique...\n",
      "🔄 Construction de l'index sémantique à partir des chunks existants...\n",
      "  🔧 Génération des embeddings pour 42 chunks...\n",
      "✅ Index sémantique prêt: 42 chunks de 6 notebooks\n",
      "================================================================================\n",
      "🚀 DÉMARRAGE DE L'AGENT UNIFIÉ - Session 5dca79bd\n",
      "📝 Requête: how can I build a system from two fragments with the Python BigDFT module?\n",
      "================================================================================\n",
      "🧠 Session continue - Sources déjà trackées: 0\n",
      "🆕 Nouvelle session démarrée\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🔄 TOUR 1/7\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🤖 Envoi de la requête au LLM...\n",
      "📊 Contexte: 2 messages\n",
      "🧠 RÉFLEXION DE L'AGENT:\n",
      "   💭 Pensée: I need to search for any relevant content or examples related to building a system from two fragments using the BigDFT module in Python. This would typically be answered by searching for semantic content in the available notebooks.\n",
      "   📋 Plan défini:\n",
      "      1. Perform a semantic search for the topic of building a system from two fragments with the BigDFT module.\n",
      "   🛠️  Outil choisi: semantic_search\n",
      "   ⚙️  Arguments: {'query': 'build a system from two fragments with the BigDFT module in Python', 'max_results': 5, 'min_confidence': 0.5}\n",
      "\n",
      "🔧 EXÉCUTION DE L'OUTIL: semantic_search\n",
      "──────────────────────────────────────────────────\n",
      "🎯 Outil: semantic_search\n",
      "📋 Arguments: {'query': 'build a system from two fragments with the BigDFT module in Python', 'max_results': 5, 'min_confidence': 0.5}\n",
      "🔍 Recherche sémantique pour: 'build a system from two fragments with the BigDFT module in Python'\n",
      "   📊 Paramètres: max_results=5, min_confidence=0.5\n",
      "   ✅ 5 résultats trouvés\n",
      "      1. 05-LinearScaling-QuickStart.ipynb - Score: 0.587 (244 tokens)\n",
      "      2. 01-QuickStart.ipynb - Score: 0.560 (390 tokens)\n",
      "      3. 01-QuickStart.ipynb - Score: 0.558 (338 tokens)\n",
      "      4. 02-N2.ipynb - Score: 0.547 (373 tokens)\n",
      "      5. 06-LinearScaling.ipynb - Score: 0.543 (358 tokens)\n",
      "📝 Nouvelles sources trackées: 5\n",
      "   ➕ [S1] 05-LinearScaling-QuickStart.ipynb (lignes 1-1) - semantic_content: semantic_chunk_1\n",
      "   ➕ [S2] 01-QuickStart.ipynb (lignes 1-1) - semantic_content: semantic_chunk_2\n",
      "   ➕ [S3] 01-QuickStart.ipynb (lignes 1-1) - semantic_content: semantic_chunk_3\n",
      "   ➕ [S4] 02-N2.ipynb (lignes 1-1) - semantic_content: semantic_chunk_4\n",
      "   ➕ [S5] 06-LinearScaling.ipynb (lignes 1-1) - semantic_content: semantic_chunk_5\n",
      "📤 Résultat formaté pour le LLM (8026 caractères)\n",
      "📊 État actuel:\n",
      "   💬 Messages dans l'historique: 3\n",
      "   📚 Sources trackées: 5\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🔄 TOUR 2/7\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🤖 Envoi de la requête au LLM...\n",
      "📊 Contexte: 4 messages\n",
      "🧠 RÉFLEXION DE L'AGENT:\n",
      "   💭 Pensée: I found relevant information on constructing a system from two fragments using the BigDFT module in Python, specifically from the results of my semantic search. Now I will compile this information to form a comprehensive answer.\n",
      "   🛠️  Outil choisi: final_answer\n",
      "   ⚙️  Arguments: {'text': \"Here's how you can build a system from two fragments using the BigDFT module in Python:\\n\\n1. **Create Atom Objects**: First, you need to define atoms. This is done by creating `Atom` objects. For example:\\n   ```python\\n   from BigDFT.Atoms import Atom\\n   \\n   at1 = Atom({'r': [0, 0, 0], 'sym': 'H', 'units': 'bohr'})\\n   at2 = Atom({'r': [0, 0, 1.4], 'sym': 'H', 'units': 'bohr'})\\n   at3 = Atom({'r': [10, 0, 0], 'sym': 'He', 'units': 'bohr'})\\n   ```\\n   This creates two hydrogen atoms and one helium atom.\\n\\n2. **Construct Fragments**: Define fragments that consist of these atoms. You can do this by using the `Fragment` class from the BigDFT module.\\n   ```python\\n   from BigDFT.Systems import Fragment, System\\n   \\n   frag_H2 = Fragment([at1, at2])\\n   frag_He = Fragment([at3])\\n   ```\\n\\n3. **Construct a System with Fragments**: Use the `System` class to combine these fragments into a single system.\\n   ```python\\n   sys = System()\\n   sys['H2:1'] = frag_H2\\n   sys['He:2'] = frag_He\\n   ```\\n   This will create a system where the `H2` fragment and the `He` fragment are treated as separate entities.\\n\\n4. **Perform a Calculation**: Once the system is set up, you can use `SystemCalculator` to perform calculations. You might set properties like grid spacing or functionals depending on your needs.\\n   ```python\\n   from BigDFT.Inputfiles import Inputfile\\n   from BigDFT.Calculators import SystemCalculator\\n   \\n   inp = Inputfile()\\n   inp.set_hgrid(0.4)\\n   inp.set_xc('PBE')\\n   calc = SystemCalculator(skip=False, verbose=False)\\n   calc.run(input=inp, name='my_calculation', sys=sys)\\n   ```\\n   Here, `SystemCalculator` runs calculations on the defined system using a specified grid spacing and exchange-correlation functional.\\n\\nThis approach is flexible and allows you to explore different configurations and setups using the BigDFT module for molecular modeling.\"}\n",
      "✅ L'agent génère sa réponse finale\n",
      "📚 Sources ajoutées: 5 références\n",
      "================================================================================\n",
      "✅ RÉPONSE STRUCTURÉE GÉNÉRÉE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ✅ Réponse finale de l'agent\n",
       "Here's how you can build a system from two fragments using the BigDFT module in Python:\n",
       "\n",
       "1. **Create Atom Objects**: First, you need to define atoms. This is done by creating `Atom` objects. For example:\n",
       "   ```python\n",
       "   from BigDFT.Atoms import Atom\n",
       "   \n",
       "   at1 = Atom({'r': [0, 0, 0], 'sym': 'H', 'units': 'bohr'})\n",
       "   at2 = Atom({'r': [0, 0, 1.4], 'sym': 'H', 'units': 'bohr'})\n",
       "   at3 = Atom({'r': [10, 0, 0], 'sym': 'He', 'units': 'bohr'})\n",
       "   ```\n",
       "   This creates two hydrogen atoms and one helium atom.\n",
       "\n",
       "2. **Construct Fragments**: Define fragments that consist of these atoms. You can do this by using the `Fragment` class from the BigDFT module.\n",
       "   ```python\n",
       "   from BigDFT.Systems import Fragment, System\n",
       "   \n",
       "   frag_H2 = Fragment([at1, at2])\n",
       "   frag_He = Fragment([at3])\n",
       "   ```\n",
       "\n",
       "3. **Construct a System with Fragments**: Use the `System` class to combine these fragments into a single system.\n",
       "   ```python\n",
       "   sys = System()\n",
       "   sys['H2:1'] = frag_H2\n",
       "   sys['He:2'] = frag_He\n",
       "   ```\n",
       "   This will create a system where the `H2` fragment and the `He` fragment are treated as separate entities.\n",
       "\n",
       "4. **Perform a Calculation**: Once the system is set up, you can use `SystemCalculator` to perform calculations. You might set properties like grid spacing or functionals depending on your needs.\n",
       "   ```python\n",
       "   from BigDFT.Inputfiles import Inputfile\n",
       "   from BigDFT.Calculators import SystemCalculator\n",
       "   \n",
       "   inp = Inputfile()\n",
       "   inp.set_hgrid(0.4)\n",
       "   inp.set_xc('PBE')\n",
       "   calc = SystemCalculator(skip=False, verbose=False)\n",
       "   calc.run(input=inp, name='my_calculation', sys=sys)\n",
       "   ```\n",
       "   Here, `SystemCalculator` runs calculations on the defined system using a specified grid spacing and exchange-correlation functional.\n",
       "\n",
       "This approach is flexible and allows you to explore different configurations and setups using the BigDFT module for molecular modeling."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## 📚 Sources consultées :\n",
       "\n",
       "[S1] 05-LinearScaling-QuickStart.ipynb (lignes 1-1) - semantic_content: semantic_chunk_1\n",
       "[S2] 01-QuickStart.ipynb (lignes 1-1) - semantic_content: semantic_chunk_2\n",
       "[S3] 01-QuickStart.ipynb (lignes 1-1) - semantic_content: semantic_chunk_3\n",
       "[S4] 02-N2.ipynb (lignes 1-1) - semantic_content: semantic_chunk_4\n",
       "[S5] 06-LinearScaling.ipynb (lignes 1-1) - semantic_content: semantic_chunk_5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### 📊 Métadonnées de la réponse\n",
       "    - ⏱️ **Temps d'exécution**: 25746ms\n",
       "    - 🔢 **Étapes utilisées**: 2/7\n",
       "    - 📚 **Sources consultées**: 5\n",
       "    - 🎯 **Niveau de confiance**: 1.00\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Conversation terminée. Pour une nouvelle question, utilisez à nouveau `/agent`.\n"
     ]
    }
   ],
   "source": [
    "%%rag\n",
    "/agent how can I build a system from two fragments with the Python BigDFT module?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
