# Project idea: LLM-powered HPC Research Assistant with remotemanager
We’re exploring a project on how LLMs can run scientific workflows on HPC systems, especially in the case when the underlying code is suitably (how?) documented and exposed via Python APIs.
The purpose of this project is to explore how well some AI models can handle building new functionality on top of an existing electronic structure code. Our hypothesis is that a code with a well defined python API will be easier to work with than the current practice of CLI interactions. Our BigDFT code, with its associated PyBigDFT python bindings and remotemanager library for running on supercomputers, will be the underlying code.

 Key tool: remotemanager (https://l_sim.gitlab.io/remotemanager/)— a Python library that submits and manages Python functions on remote supercomputers.
 Example code: (Py)BigDFT, the Python API of the BigDFT (bigdft.org) electronic-structure package, which serves as our test case for a DFT code with a Python interface.

## What we plan to do:
Use remotemanager to run tasks like atomisation energies or vibrational spectra on HPC.
Provide the agent with docs + tutorials written by developers, (e.g. BigDFT-school - https://github.com/BigDFT-group/bigdft-school).
Benchmark (how?) different models, study where documentation helps/fails, and identify ways to improve it (type hints, docstrings, examples).
Explore agentification: how to move from step-by-step prompting to autonomous agents orchestrating full workflows.

## Immediate Augmented Knowledge Agent (IAKA)

To support the goals of this project, we envision an Immediate Augmented Knowledge Agent (IAKA): a system that, when provided with external scientific and computational documentation, can compose new algorithms that it otherwise could not have generated with its baseline knowledge.
Is not just "RAG with coding" — but an **enforced augmentation loop** where the LLM is compelled to *study and model new knowledge before coding*.

### **Workflow**

1. **User request**

   * Input: *Natural language request for an algorithm*.
   * Context: *User provides external docs (scientific papers, computational references, API manuals, etc.)*.

2. **Knowledge Ingestion**

   * Documentation is **injected into a RAG pipeline**.
   * The RAG system is designed with **constraints**:

     * The LLM **must investigate and rely on the provided knowledge** (not just hallucinate).
     * **Iterative refinement**: the knowledge is not used as-is but progressively shaped into a usable model of the target algorithm.

3. **Knowledge–Algorithm Mediation**

   * The LLM interprets documentation, extracts principles, and **reframes them into computational building blocks**.
   * Example: turning math definitions into pseudocode, then code.

4. **Algorithm Synthesis**

   * The LLM composes the final algorithm, ensuring it is grounded in the injected knowledge.
   * Output: *Executable code + rationale mapping doc → algorithm*.

### **Success Criteria**

The system is considered successful if:

* The final algorithm is **correct** and **functional**.
* The algorithm **could not have been generated by the LLM’s baseline training alone**, but only by incorporating the injected docs.
* There’s a **clear audit trail** showing how the external knowledge shaped the final implementation.

---

## Hackathon target: Build a prototype notebook assistant and derive guidelines for making scientific code “LLM-friendly.”
We’re therefore tryin to gather people interested in:

LLM prompting, RAG setups & agentification

Computational chemistry / materials science

HPC workflows & Python development

Creative presentation & visualization

# Present day plan about what to do

In our preliminary discussions we have pointed out that we may need to build a framework that would assist the user towards the creation of HPC-ready actions.
In order to do so we will likely gonna need a tool that, given a human-written documentation, reads that (either with RAG or keeping a large context) and try to answer to a user queries by producing some piece of code, that will have to be *validated* by some kind of agentic tool.
For some test problems, such "validator" should act as the same level of a CI of the assistan, that should be able to answer correctly to some pre-defined questions.

Asuggestion for our next steps (Giuseppe):

* Project title
* Definition of three/four validation tests which touch different points of the tutorials or bigdft capabilities (the validation tests have to include at least a fixed query and a known correct input file/response). I think in bigdft there is a biunivocal correspondence between the input file and the DFT results. In any case it is a sufficient condition.
* Definition of a protocol to submit a new development/test in our repository (I suggest well documented notebooks as we did with LangSim to help us internal communications, memory of previous work, writing of future reports/papers)
* Definition of the LLMs to be tested
* AI Approach: we have to use an agentic system, a RAG, a combination of agents and RAG, or something else?

# HCN test (Damien)

HCN molecule frequencies. This test comes in a descriptive way and it is on purpose chosen to be implementd with the old BigDFT API, such as to challenge the capability of the framework to capture new features from the documentation. See the `titan.pdf` file.


# Raman Spectra (potential future outcome)
The task will be to build a workflow for computing raman spectra of isolated molecules. Let's first though think of all the small steps that an LLM would need to accomplish to build this workflow.

First, it should be able to make the following plans:
1) Compute the phonon modes using a finite different approximation.
2) Compute the polarizability tensor using a series of finite field calculations.
3) Compute the raman spectra using the previous approaches.
4) Search the literature for reference data to compare against.

The core computational tasks are:
1) Run a single point energy calculation with BigDFT.
2) Determine the sensitivity of the energy to the grid spacing to understand a safe minimum finite difference step.
3) Run a single point energy calculation with BigDFT on a remote computer.
4) Run a single point
5) Compute an optimized geometry with BigDFT.
6) Compute a single point energy after displacing an atom.
7) Compute the Hessian matrix and diagonalize it to get phonon modes.
8) Compute the polarizability tensor at displaced geometries along the phonon modes.
9) Calculate and plot raman intensities.


# Project teams

A (tentative) identification of the project subteams

1. Docs + Validation Team
Feed the AI with knowledge and define how to measure success.
Curate tutorials URL content (BigDFT-school, remotemanager, PyBigDFT docs)
Prepare docs/URL/html for RAG ingestion (chunking, metadata)
Define 3–4 validation tests (HCN frequencies, atomisation energies, vibrational/Raman tasks)
Provide ground truth input/output files
Maintain a notebook harness for comparison (baseline vs LLM output)
Document doc gaps + guidelines for “LLM-friendly” code
2. AI / Agent Team
2a. RAG & Interface
Build RAG pipeline (indexing docs, retrieval)
Design user interface (Jupyter notebook or lightweight frontend)
Implement augmentation loop: LLM must justify code with docs
Ensure reproducible runs on small tasks
2b. Agent Definition & Integration
Define agent roles:
Domain agent → interprets query, generates PyBigDFT functions
HPC agent → wraps into remotemanager jobs & submits
Validator agent → checks against ground truth, dry-run submission (according to doc)
Integrate with Docs+Validation team to align on tests & benchmarks
Prototype multi-agent scheduling (domain agent → HPC agent)
3. HPC & Workflow Team
Ensure real runs on supercomputers.
Wrap PyBigDFT tasks into remotemanager functions
Test remotemanager job submission & retrieval (dataset API, sanzu jupyter magic)
Run at least one validation case (HCN) end-to-end (identify HPC resources)
Support agent team with production case execution
4. Presentation Team
Draft Project main board (Motivation / Problem / Hackathon Target / Team) - miro? other?
Build slides + demo notebook
demo video (record workflow run) - the deliverable of the hackaton
Rehearse final pitch
