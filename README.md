# LARA-HPC: LArge Language Model powered HPC Research Assistant: Testing Documentation-Driven Code Interaction for PyBigDFT and remotemanager

## Abstract
We propose to build an LLM-driven research assistant that can run realistic electronic-structure simulations on High-Performance Computing (HPC) systems using the **BigDFT** code. Instead of designing a new agent framework, our focus is to explore how **documentation and code structure** affect the ability of LLMs to understand, extend and orchestrate workflows.
By leveraging the **PyBigDFT Python API**, the **remotemanager** library for job submission, and the **BigDFT-school** educational repository, we will test how well models can autonomously perform tasks such as computing atomisation energies or vibrational spectra. Our hypothesis: **a codebase with clean, Pythonic APIs and high-quality documentation will enable LLMs to perform complex tasks with minimal intervention.**

## Motivation
Electronic-structure codes remain challenging to use, especially on HPC systems where job submission and post-processing require technical expertise. LLMs are progressing rapidly as assistants, but their effectiveness depends heavily on how code and documentation are structured. Our project investigates **how to write documentation that makes scientific codes “LLM-friendly.”**

## Technical Approach
* **Target tasks**
  * Compute atomisation energies of small molecules.
  * Run vibrational spectrum calculations.
* **Workflow decomposition**
  * Break each task into input preparation, execution, log parsing and post-processing.
* **Testing with LLMs**
  * Benchmark multiple LLMs using Retrieval-Augmented Generation (RAG) over PyBigDFT documentation + BigDFT-school tutorials.
  * First test models on subtasks, then escalate to planning agents.
* **Documentation-driven learning**
  * Identify where models fail due to missing or unclear docs.
  * Iteratively improve PyBigDFT documentation (type hints, docstrings, examples, better structure).
* **HPC integration**
  * Use **remotemanager** to run jobs on remote clusters and supercomputers.
  * Leverage its `Dataset` abstraction and Jupyter magics (`%%sanzu`) for notebook-based experimentation.

## Prototype
* A notebook-based prototype where users define a scientific goal (e.g., vibrational spectrum of N₂) and an LLM assistant orchestrates the PyBigDFT workflow end-to-end on HPC.
* Parallel benchmarks across models and documentation variants to measure robustness.

## Impact
* **For researchers:** Reduce the barrier to using electronic-structure codes on HPC.
* **For developers:** Concrete guidelines on how to structure documentation so that AI agents can * effectively interact with complex scientific codes.
* **For the hackathon:** A case study showing that the quality of documentation can be as important as the quality of code in enabling AI-assisted discovery.
* **Long-term vision:** Documentation practices derived here could generalize to other simulation packages (chemistry, materials, physics).

## Immediate Augmented Knowledge Agent (IAKA)

To support the goals of this project, we envision an Immediate Augmented Knowledge Agent (IAKA): a system that, when provided with external scientific and computational documentation, can compose new algorithms that it otherwise could not have generated with its baseline knowledge.
Is not just "RAG with coding" — but an **enforced augmentation loop** where the LLM is compelled to *study and model new knowledge before coding*.

### **Workflow**

1. **User request**

   * Input: *Natural language request for an algorithm*.
   * Context: *User provides external docs (scientific papers, computational references, API manuals, etc.)*.

2. **Knowledge Ingestion**

   * Documentation is **injected into a RAG pipeline**.
   * The RAG system is designed with **constraints**:

     * The LLM **must investigate and rely on the provided knowledge** (not just hallucinate).
     * **Iterative refinement**: the knowledge is not used as-is but progressively shaped into a usable model of the target algorithm.

3. **Knowledge–Algorithm Mediation**

   * The LLM interprets documentation, extracts principles, and **reframes them into computational building blocks**.
   * Example: turning math definitions into pseudocode, then code.

4. **Algorithm Synthesis**

   * The LLM composes the final algorithm, ensuring it is grounded in the injected knowledge.
   * Output: *Executable code + rationale mapping doc → algorithm*.

### **Success Criteria**

The system is considered successful if:

* The final algorithm is **correct** and **functional**.
* The algorithm **could not have been generated by the LLM’s baseline training alone**, but only by incorporating the injected docs.
* There’s a **clear audit trail** showing how the external knowledge shaped the final implementation.

## Resources
* PyBigDFT documentation: bigdft.org
* remotemanager: https://l_sim.gitlab.io/remotemanager/
* BigDFT-school tutorials: https://github.com/BigDFT-group/bigdft-school
* HPC resources: [to be decided]
* LLM platforms: [to be discussed]

## Implementation - Project teams

### Team 1 – Docs + Validation
*Curate tutorials, prepare validation tests, provide ground truth, identify doc gaps.*

* **Members:** Damien, Thejan, Leonid, William, Luigi, Giuseppe

* **Main objectives:**
  * Curate and prepare documentation (BigDFT-school, remotemanager, PyBigDFT docs) for RAG ingestion.
  * Define 3–4 **validation tasks** (HCN frequencies, atomisation energies, vibrational/Raman spectra).
  * Provide **ground truth input/output** for those tasks.
  * Note documentation gaps (type hints, docstrings, examples) → draft **guidelines for LLM-friendly documentation**.

* **Material/ideas:**
  * BigDFT-school tutorials (GitHub repo)
  * remotemanager notebooks & docs - indicate URLs to be parsed
  * Validation tests proposed (HCN molecule frequencies, atomisation energies, vibrational/Raman)
  * Protocol for validation: notebook harness comparing LLM outputs to known reference

* **What we can do:**
  1. Collect existing tutorials + notebooks in the repo under /1-humandoc/. We do not need to copy the files, but it is enough to provide a list of URL with the actual files that will have to be "RAG-ed"
  2. Pick 2–3 initial validation tasks (start with HCN geop example - I will move the directory name).
  3. Write a draft validation notebook with input/output pairs (expected results, dry-run,...) .

* **GitHub Repo Materials:**
  * BigDFT-school tutorials (curated, chunked as needed) - provide URL of the jupyter notebooks
  * remotemanager example notebooks - URL as above
  * PyBigDFT documentaitons - same story
  * Draft validation tasks (HCN, atomisation, vibrational/Raman) with expected input/output - Some notebooks that a human would write - they should be used for comparison/validation

### Team 2 – AI / Agent
*Build RAG pipeline, define agents (domain, HPC, validator), link with validation. This group will design and test the **Immediate Augmented Knowledge Agent (IAKA)**, focusing on RAG pipelines and agent roles.*

* **Members:** Tiffany, Yoann, Youssef, Leonid, William, Etienne, Abdul, Alberto, Louis,

* **Main objectives:**
  * Design a **user interface** (e.g. Jupyter notebook + ipython magics).
  * Build a **RAG pipeline** (retrieve docs → feed LLM → grounded code generation).
  * Implement an **augmentation loop** so the LLM justifies answers with docs.
  * Define **agent roles**:
    * *Domain (DFT) agent* → interprets user queries, produces PyBigDFT functions.
    * *HPC agent* → wraps functions into remotemanager jobs & runs them.
    * *Validator agent* → checks code vs. ground truth (works with Team 1).
  * Benchmark models: baseline vs. RAG vs. agentic loop.

* **Material/ideas:**
  * Self-RAG (Shuster et al. 2023), Toolformer, Meta AI “Agents” papers (Tiffany)
  * LangChain / LlamaIndex approaches
  * Existing RAG prototype for BigDFT (Yoann)
  * LangSim ipython magics for interface (Giuseppe)
  * Regex-based doc parsing, indexing methods (Alberto)
  * MCP wrapper for remotemanager (Louis)

* **What we can do:**
  * Tiffany → Leading RAG pipeline design (chunking, metadata, doc prep strategies, enforcing doc-based reasoning).
  * Yoann → Providing agentic RAG prototype with ontology recognition (from Fortran BigDFT experience).
  * Alberto → Tools for regex-based parsing, indexing, differentiating code vs. text.
  * Giuseppe  -> Put the user interface of jupyter magic based on langsim project
  * Louis -> MCP server for remotemanager (also linked with 3)

  1. Create a `/2-aiengine/` folder in repo for RAG experiments and agent prototypes. Feel free to subfolder it
  2. Upload/document any existing RAG code or parsers (Yoann, Alberto).
  3. Upload the MCP server information
  4. Start designing *mock* user case examples - Hello world cases
  5. Move to define 1–2 **validation queries** to test on (in collaboration with Team 1).

* **GitHub Repo Materials:**
  * First RAG experiments (scripts or notebooks)
  * User Interface prototypes (LangSim magic experiments, notebooks)
  * Any doc-chunking/indexing code (regex, ontology parsers, etc.)
  * Notes/papers/resources URL (Self-RAG, Toolformer, Agents)

### Team 3 – HPC & Workflow
*Wrap PyBigDFT tasks, test remotemanager runs, run validation case end-to-end.*

* **Members:** Luigi, Vignesh, William, ,Giuseppe, Youssef , Louis

* **Main objectives:**
  * Wrap **PyBigDFT workflows** into remotemanager functions.
  * Test **remotemanager job submission & retrieval** (`%%sanzu` Jupyter magic, dataset API, MCP server, agentic approach).
  * Run at least one **validation case end-to-end** (starting with HCN  geopt/frequencies).
  * Support the AI/Agent team by executing “production” cases (vibrational spectra, atomisation energies).
  * Explore optional **multi-agent scheduling** (domain agent → HPC agent).

* **Material/ideas:**
  * Example PyBigDFT workflow (Luigi)
  * remotemanager infrastructure & notebooks
  * Focus on HCN test, remotemanager job submission, result retrieval

* **What we can do:**
  * Luigi → Example PyBigDFT workflows (local workstation + HPC reference + lab resources).
  * Giuseppe → Experience with LangSim ipython magics create pybigdft-API functions
  * Louis → MCP wrapper for remotemanager (already demonstrated remote execution of simple tasks).

  1. Set up a `/3-hpcjobs/` folder in repo.
  2. Upload Luigi’s PyBigDFT workflow example (local run).
  3. Test Louis’ MCP wrapper on a simple PyBigDFT function.
  4. Prototype remotemanager submission of a basic validation case (HCN frequencies).
  5. Secure small "HPC" resources to showcase the approach

* **GitHub Repo Materials:**
  * Example PyBigDFT workflows (local + remotemanager runs - could go in team 1 too)
  * remotemanager wrapper prototypes (Louis’ MCP wrapper, etc.)
  * Scripts for job submission/retrieval on cluster - secure some remote resources


### Team 4 – Presentation
*Build storyboard, slides, demo, and final pitch. Here we should make sure the **story of the project is clear, engaging, and compelling** for the hackathon jury. We’ll turn the technical work of the other teams into a narrative with visuals, demos, and a strong pitch.*

* **Members:** Cinthya (please confirm?), Abdul, Leonid, Giuseppe, Luigi

* **Main objectives:**
  * Complete and maintain the **Miro board** (Motivation / Problem / Hackathon Target / Teams).
  * Build **slides and video** for the final pitch.
  * Prepare the **demo notebook(s)** (with simple natural language query → HPC run).
  * Record a short **demo video** of the assistant running.
  * Rehearse the **final presentation**.

* **Material/ideas:**
  * Miro? storyboard draft with Motivation / Problem / Hackathon Target / Teams - project narrative
  * Demo notebook + optional short video
  * Wrap-up guidelines for LLM-friendly documentation

* **What we can do:**
  * Create `/4-presentation/` folder in repo (for slides, assets, demo script).
  * Correct/complete first version of the Miro board (based on hackathon submission format).
  * Write down some prose defining the project narrative to orient the presentation
  * Collect **figures, diagrams, and snippets** from Teams 1–3 as they progress.
  * Define who will present each part during the pitch.
  * Build a **slide skeleton** (intro → problem → solution → demo → impact).

* **GitHub Repo Materials:**
  * Draft of storyboard sections - narrative of the project
  * Early slide drafts / visual assets
  * Demo video snippets if available - technique for recording? Prepare working example?

### Coordination
* Coordination tasks (repo, comms, integration) will be shared across all, with Luigi and Giuseppe as main anchors.
* Everyone is welcome to contribute in more than one place.
 * The **key integration points** will be:
  * Docs+Validation  <-> AI/Agent (to align on test cases + doc ingestion)
  * AI/Agent <-> HPC (to ensure generated code actually runs with remotemanager)


## Validation tests

### HCN test (Damien)

HCN molecule frequencies. This test comes in a descriptive way and it is on purpose chosen to be implementd with the old BigDFT API, such as to challenge the capability of the framework to capture new features from the documentation. See the `titan.pdf` file.

### Raman Spectra (potential future outcome)
The task will be to build a workflow for computing raman spectra of isolated molecules. Let's first though think of all the small steps that an LLM would need to accomplish to build this workflow.

First, it should be able to make the following plans:
1) Compute the phonon modes using a finite different approximation.
2) Compute the polarizability tensor using a series of finite field calculations.
3) Compute the raman spectra using the previous approaches.
4) Search the literature for reference data to compare against.

The core computational tasks are:
1) Run a single point energy calculation with BigDFT.
2) Determine the sensitivity of the energy to the grid spacing to understand a safe minimum finite difference step.
3) Run a single point energy calculation with BigDFT on a remote computer.
4) Run a single point
5) Compute an optimized geometry with BigDFT.
6) Compute a single point energy after displacing an atom.
7) Compute the Hessian matrix and diagonalize it to get phonon modes.
8) Compute the polarizability tensor at displaced geometries along the phonon modes.
9) Calculate and plot raman intensities.